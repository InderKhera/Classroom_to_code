[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html#anxiety-of-starting-mds",
    "href": "posts/welcome/index.html#anxiety-of-starting-mds",
    "title": "From Classroom to Code",
    "section": "Anxiety of Starting MDS",
    "text": "Anxiety of Starting MDS\nWhen joining the UBC MDS program, the first thing you are made aware of is how fast paced and intense the program can be. Through this fast paced and intense learning, it is normal to feel anxious about if you are retaining the knowledge that you gained after each course ends. This can make you feel concerned if you will be ready for working in the Data Science field once you have finished this program.\nThe directors of the MDS program must have realized this as they have created a way for us to be confident in our relative expertise, through doing a collaborative project in the course “Data Science Workflows (DSCI 522)”. This course allows us to work in a group to tackle real life problems with machine learning models we have just learned.\nMy reasoning for writing this blog is to show future MDS candidates how much exactly they will have learned in this program by its halfway point using my group’s Diabetes Analysis project as the reference point. Hopefully this will lower the anxiety of future cohorts and let them enjoy the program rather than stress about their futures."
  },
  {
    "objectID": "posts/welcome/index.html#step-1-find-a-problem-that-you-believe-you-can-help-with",
    "href": "posts/welcome/index.html#step-1-find-a-problem-that-you-believe-you-can-help-with",
    "title": "From Classroom to Code",
    "section": "Step 1: Find a problem that you believe you can help with",
    "text": "Step 1: Find a problem that you believe you can help with\nBefore you can come up with a solution, you need to identify a problem. The subject my group chose to work on was Diabetes Anlysis, since all of us were interested in working in the health sector after we graduate. The purpose of our project was to build a machine learning model that accurately predict whether or not the patients in the dataset have diabetes or not."
  },
  {
    "objectID": "posts/welcome/index.html#step-2-find-the-data-and-see-what-would-set-your-research-apart-from-the-rest",
    "href": "posts/welcome/index.html#step-2-find-the-data-and-see-what-would-set-your-research-apart-from-the-rest",
    "title": "From Classroom to Code",
    "section": "Step 2: Find the Data and see what would set your research apart from the rest",
    "text": "Step 2: Find the Data and see what would set your research apart from the rest\nWe identified a dataset on Kaggle: Pima Indians Diabetes Database. This dataset was clean and there was a previous machine learning model that worked with this dataset that would could compare our model too. We agreed with the previous models created, in that using a Logistic Regression model would be the best course of action, this is due to looking at the dataset, we see that the target variable is classified with binary values: 0 for Non-Diabetic and 1 for Diabetic.\n\nWe did notice a few things that could have been done differently in prior models which we implemented into our research. The first thing we noticed is the previous models was the inclusion of outliers into the model. This will have negative effects in our model as it will influence the predicitions too much off of these observations. For example looking at the Glucose feature from the figure above we see that the Non-Diabetic class has a lot of outliers in the higher and lower range. On top of that there are values of 0 in both classes which for glucose levels should not be possible.\nFor our research we decided to use Data Validation in our analysis using libraries such as pandera to keep values of our features in predetermined ranges that are considered valid, which dropped a total of 49 outliers.\nAnother thing we identified that we wished to account for in our model was the class imbalance in the data set. Looking again at the Glucose feature in the histogram figure below we see that for most values of glucose, the count of the Diabetic class far outweights the count of the diabetic class. We implemented further validation from the deepchecks package using the ClassImbalance function to ensure that our classes were not imbalanced too much to the point that we may need other data."
  },
  {
    "objectID": "posts/welcome/index.html#step-3-creating-a-baseline-model",
    "href": "posts/welcome/index.html#step-3-creating-a-baseline-model",
    "title": "From Classroom to Code",
    "section": "Step 3: Creating a baseline model",
    "text": "Step 3: Creating a baseline model\nAfter we have cleaned our data and done our EDA, it is time to create a baseline model to compare our model to. This was done using the DummyClassifier function from the sklearn package. This model essentially guesses for each observation the most likely of the two classes. Since the class with the most observations is Non-Diabetic, the model essentially guesses all the observations are Non-Diabetic, giving this model an accuracy of 67%."
  },
  {
    "objectID": "posts/welcome/index.html#step-4-create-our-logistic-regression-model",
    "href": "posts/welcome/index.html#step-4-create-our-logistic-regression-model",
    "title": "From Classroom to Code",
    "section": "Step 4: Create our Logistic Regression model",
    "text": "Step 4: Create our Logistic Regression model\nNow after all of this work we get to finally create our own model. We use a LogisticRegression for our model, but we need to transform our data before we can put this into the model itself. Since all of our feautures are numeric, we use a StandardScaler which will remove the mean and scale the features down to unit variance. This ensures that all features contribute equally to our model and that the model isn’t biased towards features with larger scales."
  },
  {
    "objectID": "posts/welcome/index.html#step-5-hyperparameter-optimization",
    "href": "posts/welcome/index.html#step-5-hyperparameter-optimization",
    "title": "From Classroom to Code",
    "section": "Step 5: Hyperparameter Optimization",
    "text": "Step 5: Hyperparameter Optimization\nOur model still needs more fine tuning. For this we need to look at hyperparameters of the Logistic Regression model and see what would be the most efficient value for them. The hyperparameter we chose to optimize was C. C value determines how well our model fits to our training data, the higher the value of C the more it fits the training data. But we want to be careful with this as if the model is overfit on the training data, when making predictions on data outside of the training sample, we will have more inaccuracies.\nEssentially we need to have a balance between fitting the training data enough to find relationships of features and the targets but not too much where we take in random noise that will not show up in our test data. To do this we use the RandomSearchCV function that takes in a range of values for C and finds which one would fit the model the best. For our model C was optimized at 0.027."
  },
  {
    "objectID": "posts/welcome/index.html#step-6-fit-model-and-observe-feature-importance",
    "href": "posts/welcome/index.html#step-6-fit-model-and-observe-feature-importance",
    "title": "From Classroom to Code",
    "section": "Step 6: Fit model and observe Feature importance",
    "text": "Step 6: Fit model and observe Feature importance\nAfter we have finally tuned up our model as best as we can. We fit the model onto our training data and observe the coefficient of each feature.\n\nLooking at the figure above and when observing the coefficients with the highest magnitude, we see that the features with the highest influence over our predictions are Glucose and BMI. Since both of these coefficients are positive this indicates that the higher an observation’s glucose or BMI levels are, the more likely the model will predict that they are Diabetic (Outcome = 1)."
  },
  {
    "objectID": "posts/welcome/index.html#step-7-make-predictions",
    "href": "posts/welcome/index.html#step-7-make-predictions",
    "title": "From Classroom to Code",
    "section": "Step 7: Make predictions",
    "text": "Step 7: Make predictions\nUsing the predict method of our Logistic Regression model, we make predictions to see how accurate our model is.\n\nThe columns for the table above are (in order) true labels, predicted labels, prediction correctness, and predicted probabilities for the positive class.\nWe see that for the first 4 observations we guessed correctly with if they belong to the Non-Diabetic class (Outcome = 0) or if they belong to the Diabetic class (Outcome = 1). The last column shows that for the first 3 our model was not close at all to predicicting Diabetes, meaning it was rightfully confident to predict Non-Diabetic. Meanwhile for the 4th row the confidence to predict Diabetic was only 60% which is not a lot of confidence. Our final observation in the table was not predicted correctly at all.\nIn total, over all of our observation we had an accuracy rate of 75% which is not bad compared to the basline of 67% but it could definitely be better."
  },
  {
    "objectID": "posts/welcome/index.html#new-outlook",
    "href": "posts/welcome/index.html#new-outlook",
    "title": "From Classroom to Code",
    "section": "New Outlook",
    "text": "New Outlook\nAfter this model I understood that I still have a long way to go to create the complex and accurate models that I desire to make. But this doesn’t have me discouraged, after seeing how much I (along with my entire cohort) has progressed, I see that with each new block, how much we add on. Although the program is fast paced, and overwhelming at times, I am suprised by how much of the information I retain.\nThe courses are designed in a way that each block adds on to the previous courses so instead of 24 different courses it feels like 24 pieces of a puzzle that coming together. This makes me feel confident about my trajectory for the future after completing this program. Hopefully future cohorts will read this and not be as anxious as I was going into this program. You shouln’t feel anxious about your future when it comes to how much you will retain from the program, for now all you need to worry about is submitting your labs in on time!"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "From Classroom to Code: How the MDS Program Prepares You for Real-World Data Science",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 18, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Classroom to Code\n\n\nHow the MDS Program Prepares You for Real-World Data Science\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 18, 2025\n\n\nInder Khera\n\n\n\n\n\n\nNo matching items"
  }
]